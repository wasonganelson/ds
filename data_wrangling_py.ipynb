{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_wrangling_py.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasonganelson/ds/blob/master/data_wrangling_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-u5Li73arCmq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data analysis in python is made possible through pre-processing libraries(native python, numpy, pandas, scipy), visualization libraries(matplotlib, seaborn, bokeh) and machine learning libraries(sci-kit learn, tensorflow)\n",
        "\n",
        "Analysis of data can be grouped into four main stages; data wrangling, exploratory data analysis, model development, model evaluation."
      ]
    },
    {
      "metadata": {
        "id": "Ps39rPpV0obc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In data wrangling\n",
        " - we'll cover dealing with missing data\n",
        " - changing data format\n",
        " - data normalization\n",
        " - data binning\n",
        " - data encoding ... from text to numerics\n",
        "\n",
        "data wrangling is necessary as original data format might not be in a manner that enables ease of analysis"
      ]
    },
    {
      "metadata": {
        "id": "NNYah85GtF_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# DEALING WITH MISSING DATA\n",
        "\n",
        "# data source = 'https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
        "data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
        "\n",
        "# define headers to be used with data, data from source has no headers\n",
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
        "\n",
        "# read data and store in pandas dataframe\n",
        "df = pd.read_csv(data, names = headers)\n",
        "\n",
        "# view data statistics\n",
        "df.describe(include='all')\n",
        "\n",
        "# view data sample\n",
        "df.head()\n",
        "\n",
        "# from the data sample above, we note '?' values are used to identify missing values\n",
        "# we'll replace '?' with python's default missing value identifier NaN\n",
        "# below is same as ... df.replace('?', np.nan, inplace = True)\n",
        "df = df.replace('?', np.nan)\n",
        "\n",
        "# create a dataframe where nan values are stored as boolean True\n",
        "missing_values = df.isnull()\n",
        "\n",
        "# we can now loop through the missing_value dataframe to identify number of nan/ True values in every column\n",
        "columns_with_missing_values = []\n",
        "for column in missing_values:\n",
        "  if True in missing_values[column].values:\n",
        "    columns_with_missing_values.append(column)\n",
        "\n",
        "# we now have column names with nan values/ missing data\n",
        "print(columns_with_missing_values)\n",
        "\n",
        "# replace nan values in the original dataframe with mean, mode value where appropriate\n",
        "# get mean using mean() and mode using value_counts().idxmax()\n",
        "# drop price row with nan value as price is a value we intend to predict later on\n",
        "# use axis=0 to drop row, axis=1 to drop column\n",
        "df['normalized-losses'].replace(np.nan, df['normalized-losses'].astype('float').mean(), inplace = True)\n",
        "df['bore'].replace(np.nan, df['bore'].astype('float').mean(), inplace = True)\n",
        "df['stroke'].replace(np.nan, df['stroke'].astype('float').mean(), inplace = True)\n",
        "df['horsepower'].replace(np.nan, df['horsepower'].astype('float').mean(), inplace = True)\n",
        "df['peak-rpm'].replace(np.nan, df['peak-rpm'].astype('float').mean(), inplace = True)\n",
        "df['num-of-doors'].replace(np.nan, df['num-of-doors'].value_counts().idxmax(), inplace = True)\n",
        "df.dropna(subset = ['price'], axis = 0, inplace = True)\n",
        "\n",
        "# reset index, because we droped two rows ... original index is dropped as well\n",
        "df.reset_index(drop = True, inplace = True)\n",
        "\n",
        "# DATA FORMATTING\n",
        "\n",
        "# data has to be in correct format to avoid abnormal behaviour with models to be built\n",
        "# use astype() method to change column dtypes\n",
        "df[['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']] = df[['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']].astype('float') \n",
        "\n",
        "# DATA STANDARDIZATION\n",
        "\n",
        "# in some instances, you might have to change data into standard format\n",
        "# most so when data is from disparate sources i.e from m/s to km/h\n",
        "# for our case, lets convert city-mpg to city-L/100km by mathematical operation (235 divided by mpg)\n",
        "df['city-L/100km'] = 235/df['city-mpg']\n",
        "# change highway-mpg to highway-L/100km by mathematical operation (235 divided by mpg)\n",
        "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
        "df.rename(columns={'highway-mpg':'highway-L/100km'}, inplace = True)\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "\n",
        "# normalization aims to scale values of several variables to similar range\n",
        "# this is to prevent one variable from having undue/ disproportionate influence on a model\n",
        "# normalization can be through simple feature scaling, min-max scaling, z-score scaling\n",
        "# simple feature scaling is most common ... x/x~max\n",
        "df['length'] = df['length']/df['length'].max()\n",
        "df['width'] = df['width']/df['width'].max()\n",
        "df['height'] = df['height']/df['height'].max() \n",
        "# show the scaled columns\n",
        "df[['length','width','height']].head()\n",
        "\n",
        "# DATA BINNING\n",
        "\n",
        "# binning is done where we want to do grouped analysis\n",
        "# we convert continuous numerical variables into categorical bins/ groups\n",
        "# appropriate for variable with many unique numerical values i.e price\n",
        "binwidth  = (df['price'].max() - df['price'].min())/4\n",
        "bins = np.arange(df['price'].min(), df['price'].max(), binwidth)\n",
        "bin_label = ['low', 'medium', 'high']\n",
        "df['price-bin'] = pd.cut(df['price'], bins, labels=bin_label)\n",
        "df[['price', 'price-bin']].head()\n",
        "\n",
        "# draw historgram of 'price' with bins = any number\n",
        "plt.pyplot.hist(df['price'], bins = 5)\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel('price-bin')\n",
        "plt.pyplot.ylabel('no of cars')\n",
        "plt.pyplot.title('price-bins')\n",
        "\n",
        "# DUMMY/ INDICATOR VARIABLES\n",
        "\n",
        "# indicator variables are useful where non-numeric values will be used as inputs to a model\n",
        "# the non-numerics will be coded to numerics\n",
        "dumy_df = pd.get_dummies(df['fuel-type'])\n",
        "# merge dummy_df to df\n",
        "df = pd.concat([df, dumy_df], axis = 1)\n",
        "# drop fuel-type column\n",
        "df.drop(\"fuel-type\", axis = 1, inplace=True)\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AV6zG0w94GRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}